# Data Configuration Template
# This template shows all available options for configuring a dataset in Data-Science-Nailgun
# Copy this file and customize it for your specific dataset

# File locations section - specifies where your data files are located
files:
  # Path to training data (required)
  train_data: "path/to/train.csv"
  # Path to test data (required)
  test_data: "path/to/test.csv"
  # Path to validation data (optional - set to null if not available)
  validation_data: "path/to/validation.csv"  # or null

# Data configuration section - defines dataset structure and features
data:
  # ID column configuration
  id:
    # Name of the column containing unique identifiers
    column: "ID"

  # Target/label configuration
  target:
    # Name of the target column
    column: "target"
    # Number of classes for classification (use 0 for regression)
    classes: 2  # Examples: 2 (binary), 3+ (multiclass), 0 (regression)

  # Feature configuration - group features by ANY user-defined categories
  # You can use any names for your feature groups (not restricted to int/float/categorical/string)
  # Each group can contain a list of column names
  features:
    # Example: Numerical features that should be treated as integers
    numerical_int:
      - "feature1"
      - "feature2"
    # Example: Numerical features that should be treated as floats
    numerical_float:
      - "feature3"
      - "feature4"
    # Example: Categorical features for classification
    categories:
      - "category1"
      - "category2"
    # Example: Text features (if you want to keep them for reference)
    text_fields:
      - "description"
      - "notes"
    # You can add as many custom groups as needed:
    # custom_group_1:
    #   - "custom_feature_a"
    #   - "custom_feature_b"
    # custom_group_2:
    #   - "another_feature"

# Preprocessing configuration - defines data preprocessing pipeline
preprocessing:
  # Pipeline caching configuration (optional) - improves performance by caching intermediate results
  cache:
    enabled: true  # Set to true to enable caching, false to disable
    directory: ".cache"  # Directory where cache files will be stored
  
  # Imputation strategies for handling missing values
  # Configure imputation for each of your custom feature groups
  imputation:
    # Imputation for your numerical_int group
    numerical_int:
      method: "median"  # Options: "median", "mean", "most_frequent", "constant"
    # Imputation for your numerical_float group
    numerical_float:
      method: "mean"  # Options: "mean", "median", "most_frequent", "constant"
    # Imputation for your categories group
    categories:
      method: "constant"  # Options: "most_frequent", "constant"
      fill_value: -1  # Only needed for "constant" method
    # Imputation for your text_fields group (rarely used)
    text_fields:
      method: "constant"  # Options: "constant"
      fill_value: "unknown"

  # Feature transformation strategies
  # Configure transforms for each of your custom feature groups
  transforms:
    # Transforms for numerical_float group
    numerical_float:
      method: "standard_scaler"  # Options: "standard_scaler", "min_max_scaler", "robust_scaler", "none"
    # Transforms for categories group
    categories:
      method: "one_hot_encoding"  # Options: "one_hot_encoding", "label_encoding", "ordinal_encoding", "none"
      
  # Feature selection strategies
  feature_selection:
    method: "select_k_best"  # Options: "select_k_best", "variance_threshold", "rfe", null (for no feature selection)
    params:  # Parameters depend on the method selected
      # For select_k_best:
      k: 5  # Number of top features to select
      score_func: "f_classif"  # Options: "f_classif" (ANOVA F-value), "chi2", "mutual_info"
      
      # For variance_threshold (uncomment to use):
      # threshold: 0.1  # Features with variance <= threshold will be removed
      
      # For rfe (Recursive Feature Elimination) (uncomment to use):
      # n_features: 5  # Number of features to select
      # step: 1  # Number of features to remove at each iteration
      # estimator: "logistic_regression"  # Base estimator for feature importance