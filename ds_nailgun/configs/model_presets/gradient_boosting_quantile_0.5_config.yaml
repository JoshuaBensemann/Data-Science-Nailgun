# GradientBoosting Quantile Regression Model Configuration (q=0.5)

model:
  type: GradientBoostingRegressor
  library: sklearn.ensemble
  parameters:
    n_estimators: 500  # Reduced from 1000 for faster training
    max_depth: 6
    learning_rate: 0.1
    min_samples_split: 2
    min_samples_leaf: 1
    subsample: 0.8  # Added subsample for better performance
    verbose: 0  # Silent
    # Removed early stopping parameters for full training
    # Quantile regression specific parameters
    loss: 'quantile'
    alpha: 0.5  # Quantile level (0.5 = 50th percentile)

hypertuning:
  method: "halving_random_search"
  n_candidates: 25  # Reasonable candidate count
  parameters:
    max_depth: [3, 6, 9]  # Focused depth range
    learning_rate: [0.01, 0.1, 0.2]  # Key learning rates
    n_estimators: [100, 300]  # Matching estimator counts
    subsample: [0.8, 1.0]  # Reasonable subsample (only useful when < 1.0)
    min_samples_split: [2, 10]  # Reasonable split thresholds
    min_samples_leaf: [1, 5]  # Reasonable leaf sizes
    max_features: ['sqrt', None]  # Key feature selection options
    # alpha parameter removed - fixed at 0.5 in model config
  cv: 3
  scoring:
    name: 'pinball_loss'
    alpha: 0.5
  n_jobs: 1
  factor: 3
  resource: 'n_samples'