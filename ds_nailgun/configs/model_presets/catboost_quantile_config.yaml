# CatBoost Quantile Regression Model Configuration (q=0.9)

model:
  type: CatBoostRegressor
  library: catboost
  parameters:
    iterations: 500  # Reduced from 1000 for faster training
    depth: 6  # Depth of the tree
    learning_rate: 0.1
    subsample: 0.8  # Sample rate for bagging
    colsample_bylevel: 0.8  # Feature fraction per level
    random_state: 1986
    verbose: 0  # Silent mode
    # Quantile regression specific parameters
    loss_function: 'Quantile:alpha=0.9'  # Quantile loss with 0.9 quantile level

hypertuning:
  method: "halving_random_search"
  n_candidates: 25  # Reasonable candidate count
  parameters:
    depth: [4, 6, 8]  # Focused depth range
    learning_rate: [0.01, 0.1, 0.2]  # Key learning rates
    subsample: [0.8, 1.0]  # Reasonable subsample (only useful when < 1.0)
    colsample_bylevel: [0.8, 1.0]  # Feature fraction options
    l2_leaf_reg: [1, 3, 10]  # L2 regularization options
    min_data_in_leaf: [1, 10]  # Minimum samples per leaf
    border_count: [64, 128]  # Border count for categorical features
    # verbose parameter removed - not needed for tuning
  cv: 3
  scoring:
    name: 'pinball_loss'
    alpha: 0.9
  n_jobs: 1
  factor: 3
  resource: 'n_samples'
  