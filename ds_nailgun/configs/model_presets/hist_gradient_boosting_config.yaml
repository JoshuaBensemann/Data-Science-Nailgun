# HistGradientBoosting Quantile Regression Model Configuration (q=0.9)
# Note: sklearn's HistGradientBoostingRegressor does not natively support quantile loss.
# This config uses the standard 'least_squares' loss. For true quantile regression,
# consider using other models like LightGBM, XGBoost, or GradientBoostingRegressor.

model:
  type: HistGradientBoostingRegressor
  library: sklearn.ensemble
  parameters:
    max_iter: 500  # Reduced from 1000 for faster training
    max_depth: 6
    learning_rate: 0.1
    max_leaf_nodes: 31
    min_samples_leaf: 20
    random_state: 1986
    n_jobs: -1  # Use all available CPU cores
    verbose: 0  # Silent
    early_stopping: false  # Disabled to allow full training
    # Removed validation_fraction and n_iter_no_change since early_stopping is false
    # Note: loss='quantile' is not supported, using default 'least_squares'
    # For quantile regression, use other models in this directory

hypertuning:
  method: "halving_random_search"
  n_candidates: 25  # Reasonable candidate count
  parameters:
    max_depth: [3, 6, None]  # Focused depth range
    learning_rate: [0.01, 0.1, 0.2]  # Key learning rates
    max_iter: [100, 300]  # Iteration counts
    max_leaf_nodes: [31, 127]  # Leaf node options
    min_samples_leaf: [10, 20]  # Minimum samples per leaf
    l2_regularization: [0.0, 1.0]  # L2 regularization options
    # verbose parameter removed - not needed for tuning
  cv: 3
  scoring:
    name: 'neg_mean_squared_error'  # Using MSE since quantile loss not supported
  n_jobs: 1
  factor: 3
  resource: 'n_samples'
  